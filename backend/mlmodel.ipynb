{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217012be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Obtaining dependency information for lightgbm from https://files.pythonhosted.org/packages/5e/23/f8b28ca248bb629b9e08f877dd2965d1994e1674a03d67cd10c5246da248/lightgbm-4.6.0-py3-none-win_amd64.whl.metadata\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\thal-ai\\thalcare-ai\\venv\\lib\\site-packages (from lightgbm) (2.3.4)\n",
      "Requirement already satisfied: scipy in d:\\thal-ai\\thalcare-ai\\venv\\lib\\site-packages (from lightgbm) (1.16.2)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 0.8/1.5 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 22.9 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a9abefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9650cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv(r'D:\\Thal-AI\\thalcare-AI\\backend\\blood_request_ranking_dataset.csv')\n",
    "\n",
    "dataset.head()\n",
    "\n",
    "dataset[\"Relevance\"] = np.where(dataset[\"Was_Fulfilled\"] == 1, 2, np.where(dataset[\"Was_Chosen_By_User\"] == 1, 1, 0)).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b7fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1950\n",
      "[LightGBM] [Info] Number of data points in the train set: 7578, number of used features: 15\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@5: 0.696126\n",
      "[100]\tvalid_0's ndcg@5: 0.696311\n",
      "[150]\tvalid_0's ndcg@5: 0.685032\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's ndcg@5: 0.699608\n",
      "Best iteration: 71\n",
      "NDCG@3:  0.6714\n",
      "NDCG@5:  0.6996\n",
      "NDCG@10: 0.8122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import ndcg_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# Load & labels\n",
    "# -----------------------------\n",
    "dataset = pd.read_csv(r'D:\\Thal-AI\\thalcare-AI\\backend\\blood_request_ranking_dataset.csv')\n",
    "\n",
    "# graded relevance: 2 (fulfilled) > 1 (chosen) > 0\n",
    "dataset[\"Relevance\"] = np.where(\n",
    "    dataset[\"Was_Fulfilled\"] == 1, 2,\n",
    "    np.where(dataset[\"Was_Chosen_By_User\"] == 1, 1, 0)\n",
    ").astype(int)\n",
    "\n",
    "df = dataset.copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Derived features (API-safe)\n",
    "# -----------------------------\n",
    "df[\"Availability_Ratio\"] = df[\"Available_Units_For_Type\"] / df[\"Units_Requested\"].clip(lower=1)\n",
    "df[\"Staleness_Score\"] = 1.0 / (1.0 + df[\"Last_Updated_Min_Ago\"])\n",
    "\n",
    "g = df.groupby(\"Request_ID\", sort=False)\n",
    "df[\"Rel_Availability\"] = df[\"Available_Units_For_Type\"] / g[\"Available_Units_For_Type\"].transform(\"mean\").clip(lower=1e-6)\n",
    "df[\"Rel_Distance\"] = df[\"Distance_km\"] / (g[\"Distance_km\"].transform(\"min\") + 1e-6)\n",
    "\n",
    "df[\"Inv_Distance\"] = 1.0 / (1.0 + df[\"Distance_km\"])\n",
    "df[\"Urgency_Num\"] = df[\"Urgency_Level\"].map({\"Emergency\": 2, \"Routine\": 1, \"Scheduled\": 0}).fillna(1).astype(int)\n",
    "df[\"Urgency_x_Distance\"] = df[\"Urgency_Num\"] * df[\"Distance_km\"]\n",
    "\n",
    "# -----------------------------\n",
    "# Features & label\n",
    "# -----------------------------\n",
    "features = [\n",
    "    \"Distance_km\",\n",
    "    \"Available_Units_For_Type\",\n",
    "    \"Meets_Demand_Bool\",\n",
    "    \"Last_Updated_Min_Ago\",\n",
    "    \"Units_Requested\",\n",
    "    \"Blood_Group_Requested\",\n",
    "    \"Urgency_Level\",\n",
    "    \"City\",\n",
    "    \"Availability_Ratio\",\n",
    "    \"Staleness_Score\",\n",
    "    \"Rel_Availability\",\n",
    "    \"Rel_Distance\",\n",
    "    \"Inv_Distance\",\n",
    "    \"Urgency_Num\",\n",
    "    \"Urgency_x_Distance\",\n",
    "]\n",
    "label = \"Relevance\"\n",
    "\n",
    "# -----------------------------\n",
    "# Split by Request_ID (group-aware)\n",
    "# -----------------------------\n",
    "req_ids = df[\"Request_ID\"].unique()\n",
    "train_ids, test_ids = train_test_split(req_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = df[df[\"Request_ID\"].isin(train_ids)].copy()\n",
    "test_df  = df[df[\"Request_ID\"].isin(test_ids)].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Safe label encoding (fit on train, transform test)\n",
    "# -----------------------------\n",
    "encoders = {}\n",
    "for col in [\"Blood_Group_Requested\", \"Urgency_Level\", \"City\"]:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col].astype(str))\n",
    "    encoders[col] = le\n",
    "\n",
    "# -----------------------------\n",
    "# Filter invalid groups\n",
    "# -----------------------------\n",
    "def keep_valid_groups(d: pd.DataFrame, label_col: str):\n",
    "    gsize = d.groupby(\"Request_ID\").size()\n",
    "    gpos  = d.groupby(\"Request_ID\")[label_col].sum()\n",
    "    good  = gsize[(gsize >= 2) & (gpos >= 1)].index\n",
    "    return d[d[\"Request_ID\"].isin(good)].copy()\n",
    "\n",
    "train_df = keep_valid_groups(train_df, label)\n",
    "test_df  = keep_valid_groups(test_df, label)\n",
    "\n",
    "train_df = (train_df.sort_values([\"Request_ID\",\"Distance_km\"])\n",
    "                   .groupby(\"Request_ID\").head(30).reset_index(drop=True))\n",
    "test_df = (test_df.sort_values([\"Request_ID\",\"Distance_km\"])\n",
    "                  .groupby(\"Request_ID\").head(30).reset_index(drop=True))\n",
    "\n",
    "# -----------------------------\n",
    "# Matrices & groups\n",
    "# -----------------------------\n",
    "group_train = train_df.groupby(\"Request_ID\").size().to_list()\n",
    "group_test  = test_df.groupby(\"Request_ID\").size().to_list()\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[label].astype(int)\n",
    "X_test,  y_test  = test_df[features],  test_df[label].astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# LightGBM ranker (optimize NDCG@5)\n",
    "# -----------------------------\n",
    "ranker = lgb.LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    eval_at=[5],\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=3000,\n",
    "    num_leaves=95,\n",
    "    min_child_samples=30,\n",
    "    colsample_bytree=0.9,\n",
    "    subsample=0.8,\n",
    "    subsample_freq=1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "ranker.fit(\n",
    "    X_train, y_train,\n",
    "    group=group_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_group=[group_test],\n",
    "    callbacks=[early_stopping(100), log_evaluation(50)],\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation @3/@5/@10\n",
    "# -----------------------------\n",
    "def ndcg_grouped(y_true, y_score, group_sizes, k=5):\n",
    "    off = 0\n",
    "    s = []\n",
    "    for sz in group_sizes:\n",
    "        yt = y_true.iloc[off:off+sz].values\n",
    "        ys = y_score[off:off+sz]\n",
    "        s.append(ndcg_score([yt],[ys],k=k))\n",
    "        off += sz\n",
    "    return float(np.mean(s))\n",
    "\n",
    "y_pred = ranker.predict(X_test, num_iteration=ranker.best_iteration_)\n",
    "print(f\"Best iteration: {ranker.best_iteration_}\")\n",
    "print(f\"NDCG@3:  {ndcg_grouped(y_test, y_pred, group_test, k=3):.4f}\")\n",
    "print(f\"NDCG@5:  {ndcg_grouped(y_test, y_pred, group_test, k=5):.4f}\")\n",
    "print(f\"NDCG@10: {ndcg_grouped(y_test, y_pred, group_test, k=10):.4f}\")\n",
    "\n",
    "# # -----------------------------\n",
    "# # Save artifacts (for inference)\n",
    "# # -----------------------------\n",
    "# joblib.dump(ranker, r\"D:\\Thal-AI\\thalcare-AI\\backend\\ranker_api_aligned.pkl\")\n",
    "# for col, le in encoders.items():\n",
    "#     joblib.dump(le, rf\"D:\\Thal-AI\\thalcare-AI\\backend\\enc_{col}.pkl\")\n",
    "# print(\"Saved model + encoders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccd2442e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1950\n",
      "[LightGBM] [Info] Number of data points in the train set: 9467, number of used features: 15\n",
      "Best iteration: 71\n",
      "NDCG@3:  0.6714\n",
      "NDCG@5:  0.6996\n",
      "NDCG@10: 0.8122\n",
      "Final model + encoders saved.\n"
     ]
    }
   ],
   "source": [
    "# Rebuild full, filtered dataset exactly as you did for train/test\n",
    "full = df.copy()\n",
    "\n",
    "# (Re)encode categoricals on FULL data for the final model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoders = {}\n",
    "for col in [\"Blood_Group_Requested\", \"Urgency_Level\", \"City\"]:\n",
    "    le = LabelEncoder()\n",
    "    full[col] = le.fit_transform(full[col].astype(str))\n",
    "    encoders[col] = le\n",
    "\n",
    "# Keep only valid groups (>=2 candidates and >=1 positive)\n",
    "def keep_valid_groups(d, label_col):\n",
    "    gsize = d.groupby(\"Request_ID\").size()\n",
    "    gpos  = d.groupby(\"Request_ID\")[label_col].sum()\n",
    "    good  = gsize[(gsize>=2) & (gpos>=1)].index\n",
    "    return d[d[\"Request_ID\"].isin(good)].copy()\n",
    "\n",
    "full = keep_valid_groups(full, label_col=\"Relevance\")\n",
    "\n",
    "# Build X/y and group sizes\n",
    "X_all = full[features]\n",
    "y_all = full[\"Relevance\"].astype(int).values\n",
    "group_all = full.groupby(\"Request_ID\").size().to_list()\n",
    "\n",
    "# Refit final model with best iteration (71)\n",
    "import lightgbm as lgb\n",
    "final_ranker = lgb.LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    eval_at=[5],\n",
    "    learning_rate=0.03,     # same as your tuned run\n",
    "    n_estimators=71,        # lock best iteration\n",
    "    num_leaves=95,\n",
    "    min_child_samples=30,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    subsample_freq=2,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    ")\n",
    "final_ranker.fit(X_all, y_all, group=group_all)\n",
    "\n",
    "y_pred = ranker.predict(X_test, num_iteration=ranker.best_iteration_)\n",
    "print(f\"Best iteration: {ranker.best_iteration_}\")\n",
    "print(f\"NDCG@3:  {ndcg_grouped(y_test, y_pred, group_test, k=3):.4f}\")\n",
    "print(f\"NDCG@5:  {ndcg_grouped(y_test, y_pred, group_test, k=5):.4f}\")\n",
    "print(f\"NDCG@10: {ndcg_grouped(y_test, y_pred, group_test, k=10):.4f}\")\n",
    "\n",
    "\n",
    "# Save artifacts\n",
    "import joblib\n",
    "joblib.dump(final_ranker, r\"D:\\Thal-AI\\thalcare-AI\\backend\\ranker_api_aligned.pkl\")\n",
    "for col, le in encoders.items():\n",
    "    joblib.dump(le, rf\"D:\\Thal-AI\\thalcare-AI\\backend\\enc_{col}.pkl\")\n",
    "print(\"Final model + encoders saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
