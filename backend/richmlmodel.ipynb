{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dda37f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4302\n",
      "[LightGBM] [Info] Number of data points in the train set: 7573, number of used features: 36\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's ndcg@5: 0.671651\n",
      "Fold 1: NDCG@5 = 0.6717, best_iter = 64\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4303\n",
      "[LightGBM] [Info] Number of data points in the train set: 7573, number of used features: 36\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's ndcg@5: 0.698675\n",
      "Fold 2: NDCG@5 = 0.6987, best_iter = 39\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4297\n",
      "[LightGBM] [Info] Number of data points in the train set: 7574, number of used features: 36\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's ndcg@5: 0.735115\n",
      "Fold 3: NDCG@5 = 0.7351, best_iter = 190\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4304\n",
      "[LightGBM] [Info] Number of data points in the train set: 7574, number of used features: 36\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's ndcg@5: 0.699902\n",
      "Fold 4: NDCG@5 = 0.6999, best_iter = 84\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4299\n",
      "[LightGBM] [Info] Number of data points in the train set: 7574, number of used features: 36\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's ndcg@5: 0.706246\n",
      "Fold 5: NDCG@5 = 0.7062, best_iter = 16\n",
      "\n",
      "=== CV Summary ===\n",
      "NDCG@5 per fold: [0.6717, 0.6987, 0.7351, 0.6999, 0.7062]\n",
      "Mean ± Std NDCG@5: 0.7023 ± 0.0203\n",
      "Avg best_iteration: 78\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4309\n",
      "[LightGBM] [Info] Number of data points in the train set: 9467, number of used features: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 feature importances (final):\n",
      "Rel_Distance                635\n",
      "Rel_Availability            501\n",
      "Last_Updated_Min_Ago        437\n",
      "Distance_km                 366\n",
      "Fulfillment_Rate_%          358\n",
      "Patient_Satisfaction_%      351\n",
      "Urgency_x_Distance          337\n",
      "Urgency_x_Speed             314\n",
      "Adequacy_x_Staff            302\n",
      "Blood_Safety_Score_%        297\n",
      "Availability_Ratio          295\n",
      "Avg_Response_Time_Min       290\n",
      "Inv_Distance                289\n",
      "Urgency_x_Recency           284\n",
      "Total_Units                 257\n",
      "Staleness_Score             219\n",
      "Beds_Available              215\n",
      "Staffing_Level              215\n",
      "Doctors_On_Duty             182\n",
      "Available_Units_For_Type    176\n",
      "\n",
      "Saved model → D:\\Thal-AI\\thalcare-AI\\backend\\output\\ranker_auto.pkl\n",
      "Saved encoders → D:\\Thal-AI\\thalcare-AI\\backend\\output\\encoders_auto/enc_*.pkl\n",
      "Saved feature list → D:\\Thal-AI\\thalcare-AI\\backend\\output\\features_auto.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Ranker training with auto-selected features (core + derived + request-relative)\n",
    "- Reads: /mnt/data/blood_request_ranking_dataset.csv\n",
    "- GroupKFold (5 folds) by Request_ID\n",
    "- Early stopping on NDCG@5\n",
    "- Graded relevance if available, else falls back cleanly\n",
    "- Final fit on ALL data with avg best iteration\n",
    "- Saves artifacts to /mnt/data\n",
    "\"\"\"\n",
    "\n",
    "import os, json, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import ndcg_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import joblib\n",
    "\n",
    "CSV_PATH = r\"D:\\Thal-AI\\thalcare-AI\\backend\\blood_request_ranking_dataset.csv\"\n",
    "OUT_DIR  = r\"D:\\Thal-AI\\thalcare-AI\\backend\\output\"\n",
    "MODEL_OUT = os.path.join(OUT_DIR, \"ranker_auto.pkl\")\n",
    "ENC_DIR   = os.path.join(OUT_DIR, \"encoders_auto\")\n",
    "FEATS_OUT = os.path.join(OUT_DIR, \"features_auto.json\")\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities\n",
    "# -----------------------------\n",
    "def keep_valid_groups(d: pd.DataFrame, label_col: str) -> pd.DataFrame:\n",
    "    gsize = d.groupby(\"Request_ID\").size()\n",
    "    gpos  = d.groupby(\"Request_ID\")[label_col].sum()\n",
    "    good  = gsize[(gsize >= 2) & (gpos >= 1)].index\n",
    "    return d[d[\"Request_ID\"].isin(good)].copy()\n",
    "\n",
    "def ndcg_atk_grouped(y_true: np.ndarray, y_pred: np.ndarray, group_sizes: list, k=5) -> float:\n",
    "    off, sc = 0, []\n",
    "    for sz in group_sizes:\n",
    "        yt = y_true[off:off+sz]\n",
    "        yp = y_pred[off:off+sz]\n",
    "        sc.append(ndcg_score([yt], [yp], k=k))\n",
    "        off += sz\n",
    "    return float(np.mean(sc))\n",
    "\n",
    "def safe_add(col, df, fn):\n",
    "    try:\n",
    "        df[col] = fn(df)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# -----------------------------\n",
    "# Load\n",
    "# -----------------------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# -----------------------------\n",
    "# Labels & groups\n",
    "# -----------------------------\n",
    "label = None\n",
    "if \"Relevance\" in df.columns:\n",
    "    label = \"Relevance\"\n",
    "else:\n",
    "    # graded relevance if possible\n",
    "    if \"Was_Fulfilled\" in df.columns and \"Was_Chosen_By_User\" in df.columns:\n",
    "        df[\"Relevance\"] = np.where(df[\"Was_Fulfilled\"]==1, 2,\n",
    "                            np.where(df[\"Was_Chosen_By_User\"]==1, 1, 0)).astype(int)\n",
    "        label = \"Relevance\"\n",
    "    elif \"Was_Chosen_By_User\" in df.columns:\n",
    "        label = \"Was_Chosen_By_User\"\n",
    "    else:\n",
    "        raise ValueError(\"No suitable label found. Provide Relevance or Was_Chosen_By_User.\")\n",
    "\n",
    "if \"Request_ID\" not in df.columns:\n",
    "    raise ValueError(\"Request_ID column is required for grouped ranking.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Core features (only if present)\n",
    "# -----------------------------\n",
    "core_candidates = [\n",
    "    \"Distance_km\",\n",
    "    \"Available_Units_For_Type\",\n",
    "    \"Meets_Demand_Bool\",\n",
    "    \"Last_Updated_Min_Ago\",\n",
    "    \"Units_Requested\",\n",
    "    \"Blood_Group_Requested\",\n",
    "    \"Urgency_Level\",\n",
    "    \"City\",\n",
    "    \"Component_Requested\",  # optional\n",
    "]\n",
    "core = [c for c in core_candidates if c in df.columns]\n",
    "\n",
    "# -----------------------------\n",
    "# Derived features (API-safe)\n",
    "# -----------------------------\n",
    "# Availability & freshness\n",
    "safe_add(\"Availability_Ratio\", df, lambda d: d[\"Available_Units_For_Type\"] / d[\"Units_Requested\"].clip(lower=1))\n",
    "safe_add(\"Availability_Gap\",   df, lambda d: d[\"Available_Units_For_Type\"] - d[\"Units_Requested\"])\n",
    "safe_add(\"Staleness_Score\",    df, lambda d: 1.0 / (1.0 + d[\"Last_Updated_Min_Ago\"].astype(float)))\n",
    "\n",
    "# Distance shaping\n",
    "safe_add(\"Inv_Distance\", df, lambda d: 1.0 / (1.0 + d[\"Distance_km\"]))\n",
    "\n",
    "# Urgency numerics + interactions\n",
    "if \"Urgency_Level\" in df.columns:\n",
    "    urg_map = {\"Emergency\": 2, \"Routine\": 1, \"Scheduled\": 0}\n",
    "    df[\"Urgency_Num\"] = df[\"Urgency_Level\"].map(urg_map).fillna(1).astype(int)\n",
    "    if \"Distance_km\" in df.columns:\n",
    "        df[\"Urgency_x_Distance\"] = df[\"Urgency_Num\"] * df[\"Distance_km\"]\n",
    "    if \"Staleness_Score\" in df.columns:\n",
    "        df[\"Urgency_x_Recency\"] = df[\"Urgency_Num\"] * df[\"Staleness_Score\"]\n",
    "    if \"Availability_Ratio\" in df.columns:\n",
    "        df[\"Adequacy_Urgent\"] = (df[\"Urgency_Level\"].eq(\"Emergency\").astype(int) * df[\"Availability_Ratio\"])\n",
    "\n",
    "derived = [c for c in [\n",
    "    \"Availability_Ratio\",\"Availability_Gap\",\"Staleness_Score\",\"Inv_Distance\",\n",
    "    \"Urgency_Num\",\"Urgency_x_Distance\",\"Urgency_x_Recency\",\"Adequacy_Urgent\"\n",
    "] if c in df.columns]\n",
    "\n",
    "# -----------------------------\n",
    "# Request-relative features (per Request_ID)\n",
    "# -----------------------------\n",
    "if \"Available_Units_For_Type\" in df.columns and \"Distance_km\" in df.columns:\n",
    "    g = df.groupby(\"Request_ID\", sort=False)\n",
    "    df[\"Rel_Availability\"] = df[\"Available_Units_For_Type\"] / g[\"Available_Units_For_Type\"].transform(\"mean\").clip(lower=1e-6)\n",
    "    df[\"Rel_Distance\"]     = df[\"Distance_km\"] / (g[\"Distance_km\"].transform(\"min\") + 1e-6)\n",
    "    # 25th percentile proximity flag\n",
    "    q25 = g[\"Distance_km\"].transform(lambda s: np.quantile(s, 0.25) if len(s) else np.nan)\n",
    "    df[\"TopK_Proximity\"]   = (df[\"Distance_km\"] <= q25).astype(int)\n",
    "\n",
    "rel_derived = [c for c in [\"Rel_Availability\",\"Rel_Distance\",\"TopK_Proximity\"] if c in df.columns]\n",
    "\n",
    "# -----------------------------\n",
    "# Rich extras (only if present in your dataset)\n",
    "# -----------------------------\n",
    "rich_candidates = [\n",
    "    \"Total_Units\",\"Fulfillment_Rate_%\",\"Avg_Response_Time_Min\",\"Patient_Satisfaction_%\",\n",
    "    \"Blood_Safety_Score_%\",\"Emergency_Service\",\"24x7_Availability\",\n",
    "    \"Beds_Available\",\"Doctors_On_Duty\"\n",
    "]\n",
    "rich = [c for c in rich_candidates if c in df.columns]\n",
    "\n",
    "# Normalized rich-derived (if present)\n",
    "if \"Fulfillment_Rate_%\" in df.columns:\n",
    "    df[\"Fulfillment_Rate_N\"] = df[\"Fulfillment_Rate_%\"] / 100.0\n",
    "if \"Patient_Satisfaction_%\" in df.columns:\n",
    "    df[\"Satisfaction_N\"] = df[\"Patient_Satisfaction_%\"] / 100.0\n",
    "if \"Blood_Safety_Score_%\" in df.columns:\n",
    "    df[\"Safety_N\"] = df[\"Blood_Safety_Score_%\"] / 100.0\n",
    "if \"Avg_Response_Time_Min\" in df.columns:\n",
    "    df[\"Response_Speed\"] = 1.0 / (1.0 + df[\"Avg_Response_Time_Min\"])\n",
    "    if \"Urgency_Num\" in df.columns:\n",
    "        df[\"Urgency_x_Speed\"] = df[\"Urgency_Num\"] * df[\"Response_Speed\"]\n",
    "if {\"Beds_Available\",\"Doctors_On_Duty\"}.issubset(df.columns):\n",
    "    df[\"Staffing_Level\"] = df[\"Beds_Available\"].fillna(0) + df[\"Doctors_On_Duty\"].fillna(0)\n",
    "    if \"Availability_Ratio\" in df.columns:\n",
    "        df[\"Adequacy_x_Staff\"] = df[\"Availability_Ratio\"] * df[\"Staffing_Level\"]\n",
    "\n",
    "rich_derived = [c for c in [\n",
    "    \"Fulfillment_Rate_N\",\"Satisfaction_N\",\"Safety_N\",\"Response_Speed\",\"Urgency_x_Speed\",\n",
    "    \"Staffing_Level\",\"Adequacy_x_Staff\"\n",
    "] if c in df.columns]\n",
    "\n",
    "# -----------------------------\n",
    "# Final feature list\n",
    "# -----------------------------\n",
    "features = core + derived + rel_derived + rich + rich_derived\n",
    "features = list(dict.fromkeys(features))  # preserve order, drop dups\n",
    "\n",
    "# Categorical columns to encode (subset of features)\n",
    "cat_cols = [c for c in [\"Blood_Group_Requested\",\"Urgency_Level\",\"City\",\"Component_Requested\"] if c in features]\n",
    "# Boolean columns to cast as int if present\n",
    "bool_cols = [c for c in [\"Meets_Demand_Bool\",\"Emergency_Service\",\"24x7_Availability\"] if c in features]\n",
    "\n",
    "# -----------------------------\n",
    "# GroupKFold CV (5 folds)\n",
    "# -----------------------------\n",
    "groups = df[\"Request_ID\"].values\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "fold_scores, best_iters = [], []\n",
    "fold_id = 1\n",
    "\n",
    "for tr_idx, te_idx in gkf.split(df, groups=groups):\n",
    "    tr, te = df.iloc[tr_idx].copy(), df.iloc[te_idx].copy()\n",
    "\n",
    "    # Encode categoricals per fold to avoid leakage\n",
    "    encs = {}\n",
    "    for c in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        tr[c] = le.fit_transform(tr[c].astype(str))\n",
    "        mapping = {cls: i for i, cls in enumerate(le.classes_)}\n",
    "        te[c] = te[c].astype(str).map(lambda v: mapping.get(v, -1))\n",
    "        encs[c] = le\n",
    "\n",
    "    # Cast booleans to ints\n",
    "    for bc in bool_cols:\n",
    "        tr[bc] = tr[bc].astype(int)\n",
    "        te[bc] = te[bc].astype(int)\n",
    "\n",
    "    # Filter invalid groups\n",
    "    tr = keep_valid_groups(tr, label)\n",
    "    te = keep_valid_groups(te, label)\n",
    "\n",
    "    Xtr, ytr = tr[features], tr[label].astype(int).values\n",
    "    Xte, yte = te[features], te[label].astype(int).values\n",
    "    gtr = tr.groupby(\"Request_ID\").size().to_list()\n",
    "    gte = te.groupby(\"Request_ID\").size().to_list()\n",
    "\n",
    "    ranker = lgb.LGBMRanker(\n",
    "        objective=\"lambdarank\",\n",
    "        metric=\"ndcg\",\n",
    "        eval_at=[5],\n",
    "        learning_rate=0.03,\n",
    "        n_estimators=3000,\n",
    "        num_leaves=95,\n",
    "        min_child_samples=30,\n",
    "        colsample_bytree=0.9,\n",
    "        subsample=0.8,\n",
    "        subsample_freq=1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    ranker.fit(\n",
    "        Xtr, ytr,\n",
    "        group=gtr,\n",
    "        eval_set=[(Xte, yte)],\n",
    "        eval_group=[gte],\n",
    "        callbacks=[early_stopping(100), log_evaluation(0)],  # set to 50 for logs\n",
    "    )\n",
    "\n",
    "    yp = ranker.predict(Xte, num_iteration=ranker.best_iteration_)\n",
    "    ndcg5 = ndcg_atk_grouped(yte, yp, gte, k=5)\n",
    "    print(f\"Fold {fold_id}: NDCG@5 = {ndcg5:.4f}, best_iter = {ranker.best_iteration_ or 3000}\")\n",
    "    fold_scores.append(ndcg5)\n",
    "    best_iters.append(ranker.best_iteration_ or 3000)\n",
    "    fold_id += 1\n",
    "\n",
    "mean_score, std_score = float(np.mean(fold_scores)), float(np.std(fold_scores))\n",
    "avg_best = int(np.mean(best_iters))\n",
    "\n",
    "print(\"\\n=== CV Summary ===\")\n",
    "print(f\"NDCG@5 per fold: {[round(s,4) for s in fold_scores]}\")\n",
    "print(f\"Mean ± Std NDCG@5: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "print(f\"Avg best_iteration: {avg_best}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Final fit on ALL data\n",
    "# -----------------------------\n",
    "full = df.copy()\n",
    "\n",
    "# Encode categoricals on full\n",
    "os.makedirs(ENC_DIR, exist_ok=True)\n",
    "encoders = {}\n",
    "for c in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    full[c] = le.fit_transform(full[c].astype(str))\n",
    "    encoders[c] = le\n",
    "    joblib.dump(le, os.path.join(ENC_DIR, f\"enc_{c}.pkl\"))\n",
    "\n",
    "# Booleans as int\n",
    "for bc in bool_cols:\n",
    "    full[bc] = full[bc].astype(int)\n",
    "\n",
    "# Filter invalid groups\n",
    "full = keep_valid_groups(full, label)\n",
    "X_all, y_all = full[features], full[label].astype(int).values\n",
    "g_all = full.groupby(\"Request_ID\").size().to_list()\n",
    "\n",
    "final_ranker = lgb.LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    eval_at=[5],\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=avg_best,\n",
    "    num_leaves=95,\n",
    "    min_child_samples=30,\n",
    "    colsample_bytree=0.9,\n",
    "    subsample=0.8,\n",
    "    subsample_freq=1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    ")\n",
    "final_ranker.fit(X_all, y_all, group=g_all)\n",
    "\n",
    "# Save artifacts\n",
    "joblib.dump(final_ranker, MODEL_OUT)\n",
    "with open(FEATS_OUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(features, f, indent=2)\n",
    "\n",
    "# Show top importances\n",
    "fi = pd.Series(final_ranker.feature_importances_, index=X_all.columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 20 feature importances (final):\")\n",
    "print(fi.head(20).to_string())\n",
    "\n",
    "print(f\"\\nSaved model → {MODEL_OUT}\")\n",
    "print(f\"Saved encoders → {ENC_DIR}/enc_*.pkl\")\n",
    "print(f\"Saved feature list → {FEATS_OUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14477200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Request_ID</th>\n",
       "      <th>Request_Timestamp</th>\n",
       "      <th>User_Latitude</th>\n",
       "      <th>User_Longitude</th>\n",
       "      <th>Blood_Group_Requested</th>\n",
       "      <th>Component_Requested</th>\n",
       "      <th>Units_Requested</th>\n",
       "      <th>Urgency_Level</th>\n",
       "      <th>Hospital_ID</th>\n",
       "      <th>Hospital_Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Was_Fulfilled</th>\n",
       "      <th>Was_Chosen_By_User</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Availability_Ratio</th>\n",
       "      <th>Staleness_Score</th>\n",
       "      <th>Rel_Availability</th>\n",
       "      <th>Rel_Distance</th>\n",
       "      <th>Inv_Distance</th>\n",
       "      <th>Urgency_Num</th>\n",
       "      <th>Urgency_x_Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2000</td>\n",
       "      <td>11-10-2025 22:02</td>\n",
       "      <td>26.889626</td>\n",
       "      <td>75.808118</td>\n",
       "      <td>A+</td>\n",
       "      <td>Whole</td>\n",
       "      <td>4</td>\n",
       "      <td>Routine</td>\n",
       "      <td>H1011</td>\n",
       "      <td>CityCare 12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>5.032962</td>\n",
       "      <td>0.179211</td>\n",
       "      <td>1</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R2000</td>\n",
       "      <td>11-10-2025 22:02</td>\n",
       "      <td>26.889626</td>\n",
       "      <td>75.808118</td>\n",
       "      <td>A+</td>\n",
       "      <td>Whole</td>\n",
       "      <td>4</td>\n",
       "      <td>Routine</td>\n",
       "      <td>H1012</td>\n",
       "      <td>CityCare 13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.026385</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1007.097794</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>1</td>\n",
       "      <td>916.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R2000</td>\n",
       "      <td>11-10-2025 22:02</td>\n",
       "      <td>26.889626</td>\n",
       "      <td>75.808118</td>\n",
       "      <td>A+</td>\n",
       "      <td>Whole</td>\n",
       "      <td>4</td>\n",
       "      <td>Routine</td>\n",
       "      <td>H1036</td>\n",
       "      <td>CityCare 37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.045045</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>590.263088</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>1</td>\n",
       "      <td>537.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2000</td>\n",
       "      <td>11-10-2025 22:02</td>\n",
       "      <td>26.889626</td>\n",
       "      <td>75.808118</td>\n",
       "      <td>A+</td>\n",
       "      <td>Whole</td>\n",
       "      <td>4</td>\n",
       "      <td>Routine</td>\n",
       "      <td>H1057</td>\n",
       "      <td>CityCare 58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>783.405733</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>1</td>\n",
       "      <td>712.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R2000</td>\n",
       "      <td>11-10-2025 22:02</td>\n",
       "      <td>26.889626</td>\n",
       "      <td>75.808118</td>\n",
       "      <td>A+</td>\n",
       "      <td>Whole</td>\n",
       "      <td>4</td>\n",
       "      <td>Routine</td>\n",
       "      <td>H1102</td>\n",
       "      <td>CityCare 103</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>5.681312</td>\n",
       "      <td>0.162075</td>\n",
       "      <td>1</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Request_ID Request_Timestamp  User_Latitude  User_Longitude  \\\n",
       "0      R2000  11-10-2025 22:02      26.889626       75.808118   \n",
       "1      R2000  11-10-2025 22:02      26.889626       75.808118   \n",
       "2      R2000  11-10-2025 22:02      26.889626       75.808118   \n",
       "3      R2000  11-10-2025 22:02      26.889626       75.808118   \n",
       "4      R2000  11-10-2025 22:02      26.889626       75.808118   \n",
       "\n",
       "  Blood_Group_Requested Component_Requested  Units_Requested Urgency_Level  \\\n",
       "0                    A+               Whole                4       Routine   \n",
       "1                    A+               Whole                4       Routine   \n",
       "2                    A+               Whole                4       Routine   \n",
       "3                    A+               Whole                4       Routine   \n",
       "4                    A+               Whole                4       Routine   \n",
       "\n",
       "  Hospital_ID Hospital_Name  ... Was_Fulfilled  Was_Chosen_By_User  Relevance  \\\n",
       "0       H1011   CityCare 12  ...             0                   0          0   \n",
       "1       H1012   CityCare 13  ...             0                   0          0   \n",
       "2       H1036   CityCare 37  ...             0                   0          0   \n",
       "3       H1057   CityCare 58  ...             0                   0          0   \n",
       "4       H1102  CityCare 103  ...             1                   1          2   \n",
       "\n",
       "   Availability_Ratio  Staleness_Score  Rel_Availability  Rel_Distance  \\\n",
       "0                4.50         0.038760          1.200000      5.032962   \n",
       "1                2.25         0.026385          0.600000   1007.097794   \n",
       "2                2.75         0.045045          0.733333    590.263088   \n",
       "3                6.00         0.040650          1.600000    783.405733   \n",
       "4                4.00         0.153846          1.066667      5.681312   \n",
       "\n",
       "   Inv_Distance  Urgency_Num  Urgency_x_Distance  \n",
       "0      0.179211            1                4.58  \n",
       "1      0.001090            1              916.46  \n",
       "2      0.001858            1              537.14  \n",
       "3      0.001401            1              712.90  \n",
       "4      0.162075            1                5.17  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77794ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: NDCG@5=0.7062, MAP@5=0.5908\n",
      "Fold 2: NDCG@5=0.7062, MAP@5=0.5908\n",
      "Fold 3: NDCG@5=0.7062, MAP@5=0.5908\n",
      "Fold 4: NDCG@5=0.7062, MAP@5=0.5908\n",
      "Fold 5: NDCG@5=0.7062, MAP@5=0.5908\n",
      "Mean NDCG@5: 0.7062\n",
      "Mean MAP@5: 0.5908\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "map_scores = []\n",
    "ndcg_scores = []\n",
    "\n",
    "def apk(actual, predicted, k=5):\n",
    "    predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "for fold_id, (tr_idx, te_idx) in enumerate(gkf.split(df, groups=groups), 1):\n",
    "    # ... fit your model ...\n",
    "    yp = ranker.predict(Xte, num_iteration=ranker.best_iteration_)\n",
    "    # group boundaries\n",
    "    off = 0\n",
    "    fold_map_scores = []\n",
    "    for sz in gte:\n",
    "        yt = yte[off:off+sz]\n",
    "        yp_sub = yp[off:off+sz]\n",
    "        # Get sorted indices of top predictions\n",
    "        preds_ranked = np.argsort(-yp_sub)\n",
    "        # Ground truth: indices where relevance > 0\n",
    "        actual_idx = np.where(yt > 0)[0].tolist()\n",
    "        fold_map_scores.append(apk(actual_idx, preds_ranked.tolist(), k=5))\n",
    "        off += sz\n",
    "    map_fold = np.mean(fold_map_scores)\n",
    "    map_scores.append(map_fold)\n",
    "\n",
    "    ndcg5 = ndcg_atk_grouped(yte, yp, gte, k=5)\n",
    "    ndcg_scores.append(ndcg5)\n",
    "    print(f\"Fold {fold_id}: NDCG@5={ndcg5:.4f}, MAP@5={map_fold:.4f}\")\n",
    "\n",
    "print(f\"Mean NDCG@5: {np.mean(ndcg_scores):.4f}\")\n",
    "print(f\"Mean MAP@5: {np.mean(map_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca762eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1949\n",
      "[LightGBM] [Info] Number of data points in the train set: 7573, number of used features: 15\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's ndcg@5: 0.66573\n",
      "Fold 1: NDCG@5=0.6658, MAP@5=0.5442\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1950\n",
      "[LightGBM] [Info] Number of data points in the train set: 7573, number of used features: 15\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's ndcg@5: 0.688273\n",
      "Fold 2: NDCG@5=0.6883, MAP@5=0.5715\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1948\n",
      "[LightGBM] [Info] Number of data points in the train set: 7574, number of used features: 15\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's ndcg@5: 0.700097\n",
      "Fold 3: NDCG@5=0.7001, MAP@5=0.5831\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1947\n",
      "[LightGBM] [Info] Number of data points in the train set: 7574, number of used features: 15\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's ndcg@5: 0.69944\n",
      "Fold 4: NDCG@5=0.6994, MAP@5=0.5830\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1950\n",
      "[LightGBM] [Info] Number of data points in the train set: 7574, number of used features: 15\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's ndcg@5: 0.701932\n",
      "Fold 5: NDCG@5=0.7012, MAP@5=0.5858\n",
      "\n",
      "Mean NDCG@5: 0.6910\n",
      "Mean MAP@5:  0.5735\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import ndcg_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# === Load dataset ===\n",
    "df = pd.read_csv(r\"D:\\Thal-AI\\thalcare-AI\\backend\\blood_request_ranking_dataset.csv\")\n",
    "\n",
    "# === Label (graded relevance) ===\n",
    "df[\"Relevance\"] = np.where(df[\"Was_Fulfilled\"] == 1, 2,\n",
    "                    np.where(df[\"Was_Chosen_By_User\"] == 1, 1, 0)).astype(int)\n",
    "\n",
    "# === Derived features ===\n",
    "df[\"Availability_Ratio\"] = df[\"Available_Units_For_Type\"] / df[\"Units_Requested\"].clip(lower=1)\n",
    "df[\"Staleness_Score\"] = 1.0 / (1.0 + df[\"Last_Updated_Min_Ago\"])\n",
    "df[\"Inv_Distance\"] = 1.0 / (1.0 + df[\"Distance_km\"])\n",
    "df[\"Urgency_Num\"] = df[\"Urgency_Level\"].map({\"Emergency\": 2, \"Routine\": 1, \"Scheduled\": 0}).fillna(1).astype(int)\n",
    "df[\"Urgency_x_Distance\"] = df[\"Urgency_Num\"] * df[\"Distance_km\"]\n",
    "\n",
    "# === Request-relative ===\n",
    "g = df.groupby(\"Request_ID\", sort=False)\n",
    "df[\"Rel_Availability\"] = df[\"Available_Units_For_Type\"] / g[\"Available_Units_For_Type\"].transform(\"mean\").clip(lower=1e-6)\n",
    "df[\"Rel_Distance\"] = df[\"Distance_km\"] / (g[\"Distance_km\"].transform(\"min\") + 1e-6)\n",
    "\n",
    "# === Feature list ===\n",
    "features = [\n",
    "    \"Distance_km\", \"Available_Units_For_Type\", \"Meets_Demand_Bool\",\n",
    "    \"Last_Updated_Min_Ago\", \"Units_Requested\", \"Blood_Group_Requested\",\n",
    "    \"Urgency_Level\", \"City\",\n",
    "    \"Availability_Ratio\", \"Staleness_Score\", \"Inv_Distance\",\n",
    "    \"Urgency_Num\", \"Urgency_x_Distance\",\n",
    "    \"Rel_Availability\", \"Rel_Distance\"\n",
    "]\n",
    "features = [f for f in features if f in df.columns]\n",
    "\n",
    "# === Encode categoricals ===\n",
    "cat_cols = [\"Blood_Group_Requested\", \"Urgency_Level\", \"City\"]\n",
    "for c in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[c] = le.fit_transform(df[c].astype(str))\n",
    "\n",
    "# === Helpers ===\n",
    "def keep_valid_groups(d):\n",
    "    gsize = d.groupby(\"Request_ID\").size()\n",
    "    gpos = d.groupby(\"Request_ID\")[\"Relevance\"].sum()\n",
    "    good = gsize[(gsize >= 2) & (gpos >= 1)].index\n",
    "    return d[d[\"Request_ID\"].isin(good)].copy()\n",
    "\n",
    "def ndcg_atk_grouped(y_true, y_pred, group_sizes, k=5):\n",
    "    off, sc = 0, []\n",
    "    for sz in group_sizes:\n",
    "        yt, yp = y_true[off:off+sz], y_pred[off:off+sz]\n",
    "        sc.append(ndcg_score([yt], [yp], k=k))\n",
    "        off += sz\n",
    "    return np.mean(sc)\n",
    "\n",
    "def apk(actual, predicted, k=5):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "    score, hits = 0.0, 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            hits += 1.0\n",
    "            score += hits / (i+1.0)\n",
    "    return score / min(len(actual), k) if actual else 0.0\n",
    "\n",
    "def mapk(y_true, y_pred, groups, k=5):\n",
    "    off, scores = 0, []\n",
    "    for sz in groups:\n",
    "        yt, yp = y_true[off:off+sz], y_pred[off:off+sz]\n",
    "        preds_ranked = np.argsort(-yp)\n",
    "        actual_idx = np.where(yt > 0)[0].tolist()\n",
    "        scores.append(apk(actual_idx, preds_ranked.tolist(), k))\n",
    "        off += sz\n",
    "    return np.mean(scores)\n",
    "\n",
    "# === GroupKFold CV ===\n",
    "df = keep_valid_groups(df)\n",
    "groups = df[\"Request_ID\"].values\n",
    "X, y = df[features], df[\"Relevance\"].astype(int).values\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "fold_ndcg, fold_map = [], []\n",
    "\n",
    "for fold, (tr_idx, te_idx) in enumerate(gkf.split(X, y, groups), 1):\n",
    "    Xtr, Xte = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    ytr, yte = y[tr_idx], y[te_idx]\n",
    "    gtr = df.iloc[tr_idx].groupby(\"Request_ID\").size().to_list()\n",
    "    gte = df.iloc[te_idx].groupby(\"Request_ID\").size().to_list()\n",
    "\n",
    "    ranker = lgb.LGBMRanker(\n",
    "        objective=\"lambdarank\",\n",
    "        metric=\"ndcg\",\n",
    "        eval_at=[5],\n",
    "        num_leaves=63,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=2000,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    ranker.fit(\n",
    "        Xtr, ytr, group=gtr,\n",
    "        eval_set=[(Xte, yte)], eval_group=[gte],\n",
    "        callbacks=[early_stopping(100)]\n",
    "    )\n",
    "\n",
    "    yp = ranker.predict(Xte, num_iteration=ranker.best_iteration_)\n",
    "    ndcg5 = ndcg_atk_grouped(yte, yp, gte, k=5)\n",
    "    map5 = mapk(yte, yp, gte, k=5)\n",
    "    fold_ndcg.append(ndcg5)\n",
    "    fold_map.append(map5)\n",
    "    print(f\"Fold {fold}: NDCG@5={ndcg5:.4f}, MAP@5={map5:.4f}\")\n",
    "\n",
    "print(f\"\\nMean NDCG@5: {np.mean(fold_ndcg):.4f}\")\n",
    "print(f\"Mean MAP@5:  {np.mean(fold_map):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
